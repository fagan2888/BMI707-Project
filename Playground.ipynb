{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Playground.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DiGenScrGhv"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwestt/BMI707-Project/blob/master/Playground.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y7CeMu9kWuH",
        "colab_type": "text"
      },
      "source": [
        "# Playground\n",
        "\n",
        "Use this notebook to import functions and play around with specific model architectures. If you're running this in colab, we'll need to clone the repo this notebook is in, as well as the repo with the data in. \n",
        "\n",
        "**Make sure you comment out this next cell if running locally!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK7lBuMJsm-e",
        "outputId": "2fe49951-57f0-4930-bead-a1d8482cfee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Clone our project repo so we've got our code\n",
        "!git clone https://github.com/mwestt/BMI707-Project.git\n",
        "\n",
        "# Clone covid-chestxray-dataset repo for data and metadata\n",
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset.git\n",
        "\n",
        "# Move data and metadata to project repo and cd to it\n",
        "!mv covid-chestxray-dataset/images/ BMI707-Project/\n",
        "!mv covid-chestxray-dataset/metadata.csv BMI707-Project/\n",
        "%cd BMI707-Project/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'BMI707-Project' already exists and is not an empty directory.\n",
            "fatal: destination path 'covid-chestxray-dataset' already exists and is not an empty directory.\n",
            "mv: cannot stat 'covid-chestxray-dataset/images/': No such file or directory\n",
            "mv: cannot stat 'covid-chestxray-dataset/metadata.csv': No such file or directory\n",
            "/content/BMI707-Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u1CZ7qD_rax9"
      },
      "source": [
        "## Benchmark Classifier - No Augmentation\n",
        "\n",
        "First, we'll need to import the necessary functions from the codebase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_h3SqmlrGhw",
        "outputId": "ef153826-f767-4307-fc3f-4fd61a6bc64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from load_data import load_metadata, load_data\n",
        "from benchmark_classifier import train_benchmark\n",
        "\n",
        "# Load the metadata csv\n",
        "df_train, df_val = load_metadata('metadata.csv')\n",
        "df_val.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patientid</th>\n",
              "      <th>offset</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>finding</th>\n",
              "      <th>survival</th>\n",
              "      <th>intubated</th>\n",
              "      <th>intubation_present</th>\n",
              "      <th>went_icu</th>\n",
              "      <th>needed_supplemental_O2</th>\n",
              "      <th>extubated</th>\n",
              "      <th>temperature</th>\n",
              "      <th>pO2_saturation</th>\n",
              "      <th>leukocyte_count</th>\n",
              "      <th>neutrophil_count</th>\n",
              "      <th>lymphocyte_count</th>\n",
              "      <th>view</th>\n",
              "      <th>modality</th>\n",
              "      <th>date</th>\n",
              "      <th>location</th>\n",
              "      <th>folder</th>\n",
              "      <th>filename</th>\n",
              "      <th>doi</th>\n",
              "      <th>url</th>\n",
              "      <th>license</th>\n",
              "      <th>clinical_notes</th>\n",
              "      <th>other_notes</th>\n",
              "      <th>Unnamed: 27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>M</td>\n",
              "      <td>74.0</td>\n",
              "      <td>SARS</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PA</td>\n",
              "      <td>X-ray</td>\n",
              "      <td>2004</td>\n",
              "      <td>Mount Sinai Hospital, Toronto, Ontario, Canada</td>\n",
              "      <td>images</td>\n",
              "      <td>SARS-10.1148rg.242035193-g04mr34g0-Fig8a-day0....</td>\n",
              "      <td>10.1148/rg.242035193</td>\n",
              "      <td>https://pubs.rsna.org/doi/10.1148/rg.242035193</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SARS in a 74-year-old man who developed sympto...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>178</td>\n",
              "      <td>1.0</td>\n",
              "      <td>F</td>\n",
              "      <td>72.0</td>\n",
              "      <td>COVID-19</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PA</td>\n",
              "      <td>X-ray</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hospital Universitario Doctor Peset, Valencia,...</td>\n",
              "      <td>images</td>\n",
              "      <td>16660_3_1.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.eurorad.org/case/16660</td>\n",
              "      <td>CC BY-NC-SA 4.0</td>\n",
              "      <td>A 72-year-old woman admitted with acute respir...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>M</td>\n",
              "      <td>60.0</td>\n",
              "      <td>COVID-19, ARDS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PA</td>\n",
              "      <td>X-ray</td>\n",
              "      <td>2020</td>\n",
              "      <td>Spain</td>\n",
              "      <td>images</td>\n",
              "      <td>covid-19-pneumonia-rapidly-progressive-admissi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://radiopaedia.org/cases/covid-19-pneumon...</td>\n",
              "      <td>CC BY-NC-SA</td>\n",
              "      <td>Fever and odynophagia. Trip to Italy 7 days ag...</td>\n",
              "      <td>Case courtesy of Dr Edgar Lorente, Radiopaedia...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>154</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COVID-19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AP</td>\n",
              "      <td>X-ray</td>\n",
              "      <td>2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>images</td>\n",
              "      <td>radiol.2020201160.fig2d.jpeg</td>\n",
              "      <td>10.1148/radiol.2020201160</td>\n",
              "      <td>https://pubs.rsna.org/doi/full/10.1148/radiol....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>51</td>\n",
              "      <td>3.0</td>\n",
              "      <td>M</td>\n",
              "      <td>47.0</td>\n",
              "      <td>COVID-19</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PA</td>\n",
              "      <td>X-ray</td>\n",
              "      <td>March 4, 2020</td>\n",
              "      <td>Italy</td>\n",
              "      <td>images</td>\n",
              "      <td>F4341CE7-73C9-45C6-99C8-8567A5484B63.jpeg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.sirm.org/2020/03/10/covid-19-caso-34/</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male patient, 47 years old. Remote history cha...</td>\n",
              "      <td>Credit to G.Patelli , F.Besana , S. Paganoni *...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     patientid  ...  Unnamed: 27\n",
              "9            3  ...          NaN\n",
              "316        178  ...          NaN\n",
              "183         96  ...          NaN\n",
              "273        154  ...          NaN\n",
              "101         51  ...          NaN\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TL5d6i5ErGh3",
        "colab": {}
      },
      "source": [
        "# Load training and validation images from metadata csv's\n",
        "images_train, labels_train = load_data(df_train, image_size=(256, 256))\n",
        "images_val, labels_val = load_data(df_val, image_size=(256, 256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2wogSP5hrGh7"
      },
      "source": [
        "Here we'll define the Conv Net with the function `playground_model()`. Toy around with some of the parameters and see if you can get a decent-looking AUC (I'd say we're aiming for **0.7** but maybe we can do better). In general we want as simple a model as possible to be able to get perfect training accuracy, and see how good we can get our validation AUC. Some things to try:\n",
        "\n",
        "Mainly: \n",
        "- **Add extra or remove existing `Conv2D` layers.**\n",
        "- **Change number of filters in each `Conv2D` layer (first argument)**\n",
        "\n",
        "*But also:*\n",
        "- Add or remove `Dropout` layers (these layers are probably unnecessary here)\n",
        "- Change max pooling layers to average pooling\n",
        "- Smaller `Dense` layer in the final layer\n",
        "- Global average pooling instead of the final `Dense` layer\n",
        "\n",
        "**Make sure you're using a GPU Runtime!** Go to *Runtime > Change runtime type > Hardware accelerator > GPU*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tD2NtlphrGh8",
        "outputId": "b313911c-98e2-49e6-d382-867e41236b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def playground_model(input_shape=(256, 256)):\n",
        "    \"\"\"Create Keras model using Sequential API.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    model : Keras Sequential object\n",
        "        Keras Sequential model following the specified architecture.\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(input_shape[0], input_shape[1], 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu'))\n",
        "    # model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Assign the model defined above\n",
        "model = playground_model()\n",
        "\n",
        "# Train benchmark model - if you find good parameters, set `save=True`\n",
        "trained_model = train_benchmark(model, images_train, images_val, labels_train, labels_val, \n",
        "                                epochs=12, batch_size=12, save=True)\n",
        "\n",
        "# Evaluation metrics - pay attention to AUC!\n",
        "print('Validation Labels:')\n",
        "print(labels_val)\n",
        "\n",
        "print('Predicted Labels:')\n",
        "y_pred = trained_model.predict_classes(images_val, verbose=1).T[0]\n",
        "print(y_pred)\n",
        "\n",
        "print('Predicted Probabilities')\n",
        "y_probs = trained_model.predict(images_val, verbose=1).T[0]\n",
        "print(y_probs)\n",
        "\n",
        "print('Prediction AUC')\n",
        "print(roc_auc_score(labels_val, y_probs))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 189 samples, validate on 94 samples\n",
            "Epoch 1/12\n",
            "189/189 [==============================] - 2s 8ms/step - loss: 7.6271 - accuracy: 0.7037 - val_loss: 0.5660 - val_accuracy: 0.8298\n",
            "Epoch 2/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.5165 - accuracy: 0.7884 - val_loss: 0.5277 - val_accuracy: 0.8191\n",
            "Epoch 3/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.4702 - accuracy: 0.8307 - val_loss: 0.5062 - val_accuracy: 0.8191\n",
            "Epoch 4/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.3182 - accuracy: 0.8730 - val_loss: 0.5478 - val_accuracy: 0.8191\n",
            "Epoch 5/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.2137 - accuracy: 0.9153 - val_loss: 0.6030 - val_accuracy: 0.7128\n",
            "Epoch 6/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.1983 - accuracy: 0.9259 - val_loss: 0.6171 - val_accuracy: 0.7340\n",
            "Epoch 7/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.1845 - accuracy: 0.9524 - val_loss: 0.6624 - val_accuracy: 0.7447\n",
            "Epoch 8/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.1363 - accuracy: 0.9577 - val_loss: 0.8035 - val_accuracy: 0.6170\n",
            "Epoch 9/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.1308 - accuracy: 0.9683 - val_loss: 0.9004 - val_accuracy: 0.6596\n",
            "Epoch 10/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0702 - accuracy: 0.9788 - val_loss: 1.5836 - val_accuracy: 0.5426\n",
            "Epoch 11/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0544 - accuracy: 0.9841 - val_loss: 1.2771 - val_accuracy: 0.7766\n",
            "Epoch 12/12\n",
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0604 - accuracy: 0.9788 - val_loss: 1.8081 - val_accuracy: 0.5532\n",
            "Validation Labels:\n",
            "[0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Predicted Labels:\n",
            "94/94 [==============================] - 0s 2ms/step\n",
            "[0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1\n",
            " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0\n",
            " 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1]\n",
            "Predicted Probabilities\n",
            "94/94 [==============================] - 0s 2ms/step\n",
            "[4.4070628e-01 7.5868855e-04 7.2422606e-01 9.9999988e-01 8.5349840e-01\n",
            " 9.2183119e-03 1.0000000e+00 1.3513444e-01 8.5694734e-03 9.9999952e-01\n",
            " 5.8678173e-02 8.2119100e-02 3.5692111e-01 5.2816820e-01 9.8698843e-01\n",
            " 7.3114461e-01 2.4217683e-01 9.9999988e-01 7.3783910e-01 8.5749310e-01\n",
            " 6.1490923e-01 1.0000000e+00 3.6469109e-02 8.8100028e-01 9.9998498e-01\n",
            " 1.6992842e-01 3.8444015e-01 2.9256954e-04 9.8942739e-01 6.3006734e-03\n",
            " 2.1146452e-01 9.0285653e-01 3.2527190e-01 1.7533766e-01 3.8927110e-06\n",
            " 1.0000000e+00 9.7041839e-01 9.6704674e-01 4.0385443e-01 1.8949163e-01\n",
            " 2.7203882e-02 3.6661568e-01 3.4782696e-01 7.5756974e-04 1.9823140e-01\n",
            " 8.4963828e-01 4.2469341e-02 1.1351063e-01 1.4096424e-01 9.9940610e-01\n",
            " 6.9689870e-02 7.5864308e-02 2.6579383e-01 5.2755535e-01 4.3172210e-02\n",
            " 2.8983261e-02 1.7925517e-03 2.4073617e-07 8.3124828e-01 8.5697633e-01\n",
            " 3.8836500e-01 6.1046380e-01 7.6821461e-02 6.2688127e-02 3.9381725e-01\n",
            " 1.2859556e-01 4.2085010e-01 9.4149303e-01 9.6717083e-01 9.7784722e-01\n",
            " 6.1474726e-02 1.2763585e-02 2.6648372e-04 9.1557368e-04 1.3448188e-06\n",
            " 9.9999940e-01 7.8049207e-01 3.2265194e-02 2.9905248e-03 6.6004968e-01\n",
            " 2.2245841e-02 5.9691119e-01 4.0927425e-01 6.5128249e-01 9.9996686e-01\n",
            " 2.6350027e-01 1.1138720e-03 4.2216547e-02 7.7310003e-02 9.9051917e-01\n",
            " 9.9998784e-01 1.0000000e+00 8.6391050e-01 9.9970287e-01]\n",
            "Prediction AUC\n",
            "0.6514423076923077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZEjw_nrBrGh_"
      },
      "source": [
        "## Loading Model Workflow\n",
        "\n",
        "Feel free to add any code cells following this, for example loading your saved models and then using them to make predictions. For example, here's one I made earlier! Just save your own model with `save=True` in `train_benchmark()` above,\n",
        "and replace the filepath below with your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CPr5XBBFrGiB",
        "outputId": "a3fb5e25-d8d2-41ac-e759-a201582bd36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# Load saved model and print summary information\n",
        "loaded_model = load_model('model_bench_2020_04_26_00_37_24.h5')    \n",
        "print(loaded_model.summary())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 256)     73984     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 128, 128, 256)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1048576)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               134217856 \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 134,292,865\n",
            "Trainable params: 134,292,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hoT7hVWkrGiF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b21e4fe9-b3d4-478a-e9d4-b4c8172852ef"
      },
      "source": [
        "print('Validation Labels:')\n",
        "print(labels_val)\n",
        "\n",
        "print('Predicted Labels:')\n",
        "y_pred = loaded_model.predict_classes(images_val, verbose=1).T[0]\n",
        "print(y_pred)\n",
        "\n",
        "print('Predicted Probabilities')\n",
        "y_probs = loaded_model.predict(images_val, verbose=1).T[0]\n",
        "# print(y_probs)\n",
        "\n",
        "print('Prediction AUC')\n",
        "print(roc_auc_score(labels_val, y_probs))\n",
        "\n",
        "print('Prediction Accuracy')\n",
        "print(sum(y_pred == labels_val) / len(labels_val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Labels:\n",
            "[0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Predicted Labels:\n",
            "94/94 [==============================] - 0s 2ms/step\n",
            "[1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Predicted Probabilities\n",
            "94/94 [==============================] - 0s 2ms/step\n",
            "Prediction AUC\n",
            "0.672275641025641\n",
            "Prediction Accuracy\n",
            "0.7340425531914894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rOEfiDdkWug",
        "colab_type": "text"
      },
      "source": [
        "# Training with Data Augmentation\n",
        "\n",
        "The following cell is much like the previous section, but we will now train on augmented data using Keras data augmentation, rather than on the images directly. There are a number of augmentation parameters to explore, take a look at the Keras documentation for the [`ImageDataGenerator` class](https://keras.io/preprocessing/image/) for potential arguments to try."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L_nGdlKkWug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "f9a6bdd9-5a36-487b-dc27-f388f0c388d6"
      },
      "source": [
        "from load_data import data_generator_from_dataframe, ValidImageDataGenerator\n",
        "from benchmark_classifier import train_augmented_benchmark\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_size = (256, 256)\n",
        "batch_size = 8\n",
        "epochs = 12\n",
        "\n",
        "# Effective size of training set\n",
        "n_train_eff = 200\n",
        "n_val_eff = 60\n",
        "steps_per_epoch = n_train_eff // batch_size\n",
        "validation_steps = n_val_eff // batch_size\n",
        "\n",
        "# Define ImageDataGenerator for training - tweak these arguments\n",
        "train_datagen = ImageDataGenerator(rescale=1./255\n",
        "                                   )\n",
        "\n",
        "train_generator = data_generator_from_dataframe(train_datagen, df_train,\n",
        "                                                image_size=image_size, \n",
        "                                                batch_size=batch_size)\n",
        "\n",
        "# Simple generator for validation\n",
        "validation_generator = data_generator_from_dataframe(ValidImageDataGenerator(), \n",
        "                                                     df_val, image_size=image_size, \n",
        "                                                     batch_size=batch_size)\n",
        "\n",
        "# Reinstantiate model\n",
        "model = playground_model(input_shape=image_size)\n",
        "\n",
        "# Train model with augmented data\n",
        "trained_model_aug = train_augmented_benchmark(model, train_generator, \n",
        "                                              validation_generator,\n",
        "                                              epochs=epochs, \n",
        "                                              steps_per_epoch=steps_per_epoch, \n",
        "                                              validation_steps=validation_steps, \n",
        "                                              save=False)\n",
        "\n",
        "# Evaluation metrics - once again, pay attention to AUC!\n",
        "print('Validation Labels:')\n",
        "print(labels_val)\n",
        "\n",
        "# images_val, labels_val = load_data(df_val, image_size=image_size)\n",
        "print('Predicted Labels:')\n",
        "y_pred = trained_model_aug.predict_classes(images_val, verbose=1).T[0]\n",
        "print(y_pred)\n",
        "\n",
        "print('Predicted Probabilities')  \n",
        "y_probs = trained_model_aug.predict(images_val, verbose=1).T[0]\n",
        "print(y_probs)\n",
        "\n",
        "print('Prediction AUC')\n",
        "print(roc_auc_score(labels_val, y_probs))\n",
        "\n",
        "print('Prediction Accuracy')\n",
        "print(sum(y_pred == labels_val) / len(labels_val))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 189 validated image filenames.\n",
            "Found 94 validated image filenames.\n",
            "Epoch 1/12\n",
            "25/25 [==============================] - 10s 413ms/step - loss: 1.9868 - accuracy: 0.7423 - val_loss: 0.1333 - val_accuracy: 0.8036\n",
            "Epoch 2/12\n",
            "25/25 [==============================] - 9s 344ms/step - loss: 0.4871 - accuracy: 0.7900 - val_loss: 0.1729 - val_accuracy: 0.8889\n",
            "Epoch 3/12\n",
            "25/25 [==============================] - 9s 371ms/step - loss: 0.3018 - accuracy: 0.8579 - val_loss: 1.3126 - val_accuracy: 0.7857\n",
            "Epoch 4/12\n",
            "25/25 [==============================] - 10s 402ms/step - loss: 0.2005 - accuracy: 0.9239 - val_loss: 0.8198 - val_accuracy: 0.7037\n",
            "Epoch 5/12\n",
            "25/25 [==============================] - 7s 286ms/step - loss: 0.1028 - accuracy: 0.9588 - val_loss: 0.6131 - val_accuracy: 0.6964\n",
            "Epoch 6/12\n",
            "25/25 [==============================] - 12s 468ms/step - loss: 0.1478 - accuracy: 0.9450 - val_loss: 0.5267 - val_accuracy: 0.6481\n",
            "Epoch 7/12\n",
            "25/25 [==============================] - 7s 265ms/step - loss: 0.1524 - accuracy: 0.9492 - val_loss: 0.3287 - val_accuracy: 0.9259\n",
            "Epoch 8/12\n",
            "25/25 [==============================] - 10s 386ms/step - loss: 0.0646 - accuracy: 0.9746 - val_loss: 0.7205 - val_accuracy: 0.7321\n",
            "Epoch 9/12\n",
            "25/25 [==============================] - 10s 403ms/step - loss: 0.0384 - accuracy: 0.9848 - val_loss: 1.0886 - val_accuracy: 0.7037\n",
            "Epoch 10/12\n",
            "25/25 [==============================] - 9s 341ms/step - loss: 0.1752 - accuracy: 0.9797 - val_loss: 1.0572 - val_accuracy: 0.6786\n",
            "Epoch 11/12\n",
            "25/25 [==============================] - 10s 410ms/step - loss: 0.1598 - accuracy: 0.9645 - val_loss: 0.2544 - val_accuracy: 0.7963\n",
            "Epoch 12/12\n",
            "25/25 [==============================] - 8s 315ms/step - loss: 0.2570 - accuracy: 0.9639 - val_loss: 1.0114 - val_accuracy: 0.7407\n",
            "Validation Labels:\n",
            "[0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Predicted Labels:\n",
            "94/94 [==============================] - 0s 2ms/step\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Predicted Probabilities\n",
            "94/94 [==============================] - 0s 2ms/step\n",
            "[0.99818605 0.9937093  0.99113876 1.         0.99912804 0.96328217\n",
            " 1.         0.9907354  0.9922792  1.         0.9729317  0.9809544\n",
            " 0.9996302  0.9941824  0.9999926  0.99839646 0.99998295 1.\n",
            " 0.9965048  0.99980444 0.99991214 1.         0.999178   0.9957593\n",
            " 1.         0.9773425  0.99984527 0.61867255 0.9999541  0.96994376\n",
            " 0.9764464  0.9999926  0.9914801  0.99808156 0.99850357 1.\n",
            " 0.9995245  0.9999994  0.99349374 0.98438984 0.88838583 0.9998147\n",
            " 0.9438886  0.9937109  0.9837646  0.98231125 0.9994313  0.9820218\n",
            " 0.9999943  1.         0.9959066  0.99027014 0.98021483 0.9738858\n",
            " 0.9930225  0.9003919  0.4119176  1.         0.9968258  0.9988716\n",
            " 0.98546904 0.99999964 0.9762573  0.9772866  0.98849887 0.9627642\n",
            " 0.99177223 0.9971085  0.9999999  1.         0.95059866 0.83393675\n",
            " 0.62024975 0.8809058  0.00400054 1.         0.99806887 0.900046\n",
            " 0.95983887 0.99263704 0.934794   0.9999405  0.9977436  0.9999256\n",
            " 0.9999999  0.9996284  0.98853326 0.979293   0.9493525  0.99999976\n",
            " 1.         1.         0.99594253 0.99999976]\n",
            "Prediction AUC\n",
            "0.7091346153846154\n",
            "Prediction Accuracy\n",
            "0.8085106382978723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjkuxL6qkWul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}